{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asutoshp10/GAN/blob/main/cGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h68X1FIYxeEt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "from keras import Sequential,Model,Input\n",
        "from keras.datasets.cifar10 import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfgn08PU7CVZ",
        "outputId": "49b9b411-a758-424b-aded-9a4e7b30884c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_tr,y_tr),(x_test,y_test)=load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxaa7NJB7Sl5"
      },
      "outputs": [],
      "source": [
        "x_tr=(x_tr-127.5)/127.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3ykdQ8k7oCR"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples(dataset,n_samples):\n",
        "    ix=np.random.randint(0,dataset.shape[0],n_samples)\n",
        "    x1=dataset[ix]\n",
        "    x2=y_tr[ix]\n",
        "    x=[x1,x2]\n",
        "    y=np.ones((n_samples,1))\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PGB8m2J8Paq"
      },
      "outputs": [],
      "source": [
        "def discriminator(in_shape=(32,32,3),n_classes=10):\n",
        "  input_shape=Input(shape=(1,))\n",
        "  in_dim=Input(shape=in_shape)\n",
        "  d=Embedding(n_classes,50)(input_shape)\n",
        "  d=Dense(in_shape[0]*in_shape[1])(d)\n",
        "  d=Reshape((in_shape[0],in_shape[1],1))(d)\n",
        "\n",
        "  merge=Concatenate()([in_dim,d])\n",
        "  d=Conv2D(128,(3,3),padding='same',strides=2)(merge)\n",
        "  d=LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d=Conv2D(128,(3,3),padding='same',strides=2)(d)\n",
        "  d=LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d=Conv2D(128,(3,3),padding='same',strides=2)(d)\n",
        "  d=LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "  d=Flatten()(d)\n",
        "  d=Dropout(0.4)(d)\n",
        "  d=Dense(1,activation='sigmoid')(d)\n",
        "\n",
        "  model=Model([in_dim,input_shape],d)\n",
        "  opt=Adam(lr=0.0002,beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykP8drm08fuu"
      },
      "outputs": [],
      "source": [
        "def generator(latent_dim=100,n_classes=10):\n",
        "  in_latent=Input(shape=(latent_dim))\n",
        "  in_class=Input(shape=(1,))\n",
        "  c=Embedding(n_classes,50)(in_class)\n",
        "  c=Dense(4*4)(c)\n",
        "  c=Reshape((4,4,1))(c)\n",
        "\n",
        "  l=Dense(4*4*256)(in_latent)\n",
        "  l=LeakyReLU(alpha=0.2)(l)\n",
        "  l=Reshape((4,4,256))(l)\n",
        "\n",
        "  merge=Concatenate()([l,c])\n",
        "  g=Conv2DTranspose(128,(4,4),strides=2,padding='same')(merge)\n",
        "  g=LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "  g=Conv2DTranspose(128,(4,4),strides=2,padding='same')(g)\n",
        "  g=LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "  g=Conv2DTranspose(128,(4,4),strides=2,padding='same')(g)\n",
        "  g=LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "  g=Conv2D(3,(3,3),padding='same',activation='tanh')(g)\n",
        "\n",
        "  return Model([in_latent,in_class],g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGW_XMFAEEmt"
      },
      "outputs": [],
      "source": [
        "def generate_latent_dim(latent_dim, n_classes, n_samples):\n",
        "  x2 = np.random.randint(0, n_classes, n_samples)\n",
        "  x1 = np.random.randn(n_samples,latent_dim)\n",
        "  return [x1,x2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akU3RgF6EqCO"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(g_model,latent_dim=100,n_classes=10,n_samples=64):\n",
        "    [l1,l2]=generate_latent_dim(latent_dim,n_classes,n_samples)\n",
        "    y=np.zeros((n_samples,1))\n",
        "    x1=g_model.predict([l1,l2])\n",
        "    return [x1,l2],y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC6L1EpHhhso"
      },
      "outputs": [],
      "source": [
        "def gan(g_model,d_model):\n",
        "  d_model.trainable=False\n",
        "  #classes=Input(shape=(1,))\n",
        "  #latent=Input(shape=(100,))\n",
        "  latent,classes=g_model.input\n",
        "  g_output=g_model.output\n",
        "\n",
        "  d=d_model([g_output,classes])\n",
        "  model=Model([latent,classes],d)\n",
        "  opt=Adam(lr=0.0002,beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=opt)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQNqBDHY-VZs"
      },
      "outputs": [],
      "source": [
        "def train(gan_model,g_model,d_model,dataset,latent_dim=100,n_epochs=250,n_batch=128):\n",
        "  bat_per_epo=int(dataset.shape[0]/n_batch)\n",
        "  half_batch=int(n_batch/2)\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "      x_real,y_real=generate_real_samples(dataset,half_batch)\n",
        "      d_loss1,d_acc1=d_model.train_on_batch(x_real,y_real)\n",
        "      x_fake,y_fake=generate_fake_samples(g_model,latent_dim,10,half_batch)\n",
        "      d_loss2,d_acc2=d_model.train_on_batch(x_fake,y_fake)\n",
        "\n",
        "      l=generate_latent_dim(latent_dim,10,n_batch)\n",
        "      #print(l1.shape,l2.shape)\n",
        "      y_gan=np.ones((n_batch,1))\n",
        "      g_loss=gan_model.train_on_batch(l,y_gan)\n",
        "\n",
        "      print(f'epoch:{i+1}/{n_epochs},batch:{j+1}/{bat_per_epo},d_loss1:{d_loss1},d_loss2:{d_loss2},g_loss:{g_loss}')\n",
        "    if j%10==0:\n",
        "      generate_plot(g_model,latent_dim,i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKeLfuLxAPed"
      },
      "outputs": [],
      "source": [
        "def generate_plot(g_model,latent_dim,epoch_no):\n",
        "  l=generate_latent_dim(latent_dim,10,100)\n",
        "  l2=[]\n",
        "  for i in range(10):\n",
        "    for j in range(10):\n",
        "      l2.append(j)\n",
        "\n",
        "  x=g_model.predict([l[0],np.array(l2)])\n",
        "  for i in range(100):\n",
        "    plt.subplot(10,10,i+1)\n",
        "    plt.axis='off'\n",
        "    plt.imshow(x[i])\n",
        "  g_model.save(f'model_{epoch_no}.h5')\n",
        "  plt.savefig(f'plot_{epoch_no}.png')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aleZh4OTCYnf"
      },
      "outputs": [],
      "source": [
        "g_model=generator()\n",
        "d_model=discriminator()\n",
        "gan_model=gan(g_model,d_model)\n",
        "train(gan_model,g_model,d_model,x_tr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOm2ohd//ltZ+nLdov8JRbV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}